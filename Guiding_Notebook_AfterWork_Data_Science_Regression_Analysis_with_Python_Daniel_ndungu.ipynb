{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Guiding Notebook AfterWork Data Science: Regression Analysis with Python -Daniel ndungu",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meaFX6VfQh5I"
      },
      "source": [
        "## <font color='#2F4F4F'>1. Defining the Question</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTX4bMspQh5K"
      },
      "source": [
        "### a) Specifying the Data Analysis Question\n",
        "\n",
        "Perform multiple linear regression to predict the price of a house. Make sure to check for assumptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s2gnvcjQh5L"
      },
      "source": [
        "### b) Defining the Metric for Success\n",
        "\n",
        "The project will be a success when we are able to create a multiple linear regression model that fits at least 80% of the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E23qkTvTQh5M"
      },
      "source": [
        "### c) Understanding the Context \n",
        "\n",
        "Knightly Frankly is an estate agency, residential and commercial property consultancy\n",
        "founded in London by John Knight, Howard Frank and William Rutley in 1896.\n",
        "Together with its New York-based affiliate Newmark, Knightly Frankly is one of the\n",
        "world's largest global property consultancies.\n",
        "As a data scientist working for the agency, you have been put to task to help develop a\n",
        "solution that would allow the agency to price its properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk6TpqrfQh5M"
      },
      "source": [
        "### d) Recording the Experimental Design\n",
        "\n",
        "1. Load datasets and libraries\n",
        "2. Clean data\n",
        "3. Perform univariate and bivariate analysis\n",
        "4. Check that the assumptions of multiple linear regression aren't violated\n",
        "5. Perform multiple linear regression\n",
        "6. Summarize findings\n",
        "7. Provide recommendations\n",
        "8. Challenge the solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__PaXEtKQh5N"
      },
      "source": [
        "### e) Data Relevance\n",
        "\n",
        "The dataset provided is appropriate and relevant to the research question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8rSBtAyQh5O"
      },
      "source": [
        "## <font color='#2F4F4F'>2. Data Cleaning & Preparation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZy6qDmHQh5O"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max.columns', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GHFyUXltQh5T"
      },
      "source": [
        "house = pd.read_csv('house_data.csv')\n",
        "house.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tu6IRTPQh5Z"
      },
      "source": [
        "# check dataset shape\n",
        "house.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0oolCubQh5d"
      },
      "source": [
        "# chekc data types\n",
        "house.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlarjfW3Qh5g"
      },
      "source": [
        "We will drop the 'id' and 'date' variables and then drop any duplicated values so that it will be easier to work with the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pyGVuJoQh5h"
      },
      "source": [
        "house = house.drop(columns = ['id', 'date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDhro9kWQh5p"
      },
      "source": [
        "# dropping duplicates, if any\n",
        "house.drop_duplicates(inplace = True)\n",
        "house.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBlNxg15Qh5t"
      },
      "source": [
        "# check for missing data\n",
        "house.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgtiibCgQh5w"
      },
      "source": [
        "There are no missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTiv2tLCQh5x"
      },
      "source": [
        "## <font color='#2F4F4F'>3. Data Analysis</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtX54cfZQh5x"
      },
      "source": [
        "For our analysis, we will check the assumptions of multiple linear regression which include:\n",
        "1. There must be a linear relationship between the independent variables and the target variable.\n",
        "2. Few or no outliers.\n",
        "3. Little to no multicollinearity.\n",
        "4. Homoscedasticity - variance of error terms must be similar across the independent variables.\n",
        "5. All residuals must be normally distributed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUcQJF-9Qh5y"
      },
      "source": [
        "### 3.1 Checking linearity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BztUQ5vMQh5z"
      },
      "source": [
        "# create list to store column names to test against 'price'\n",
        "house_columns = house.columns.to_list()\n",
        "house_columns.remove('price')\n",
        "len(house_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "okBGvNGsQh52"
      },
      "source": [
        "# creating scatterplots to observe the relationship between price and the variables\n",
        "fig, axes = plt.subplots(nrows = 9, ncols = 2, figsize = (12, 30))\n",
        "\n",
        "for ax, col in zip(axes.flatten(), house_columns):\n",
        "    sns.scatterplot(house[col], house['price'], ax = ax)\n",
        "    plt.xlabel(\"{}\".format(col))\n",
        "    plt.ylabel(\"price\")\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSklY_jFQh56"
      },
      "source": [
        "What have you noticed? What will you do next?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZX1cZ1SQh57"
      },
      "source": [
        "### 3.2 Checking for outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCVFY0n2Qh57"
      },
      "source": [
        "# create a boxplot to visualize the outliers\n",
        "YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En57sZF4Qh5-"
      },
      "source": [
        "What observations can you make? What actions are you going to take next?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNOZq_cEQh6B"
      },
      "source": [
        "### 3.3 Checking multicollinearity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhKDgzytQh6C"
      },
      "source": [
        "# create a heatmap of the correlations\n",
        "YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6xUq7fKQh6I"
      },
      "source": [
        "# check VIF scores\n",
        "YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IUUV10uQh6N"
      },
      "source": [
        "What have you noticed? What actions are you going to take next regarding this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-dNNwsMQh6N"
      },
      "source": [
        "## <font color='#2F4F4F'>4. Data Modeling</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5MnZUDwQh6P"
      },
      "source": [
        "# split into features (X) and label (Y)\n",
        "YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUYhwTDxQh6X"
      },
      "source": [
        "# split into 80-20 train and test sets\n",
        "YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPyFrF8XQh6k"
      },
      "source": [
        "# fit regressor to data and make predictions\n",
        "YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5e63GziQh6s"
      },
      "source": [
        "# evaluate RMSE and r-squared scores\n",
        "YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70ZaR5nfQh6x"
      },
      "source": [
        "What conclusions have you drawn?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYZpWqulQh6y"
      },
      "source": [
        "### 4.1 Test for normality and homoscedasticity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXzW5UAcQh6y"
      },
      "source": [
        "# create a dataframe of residuals\n",
        "YOUR CODE HERE\n",
        "\n",
        "# plotting our residuals\n",
        "YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzXLIpY3Qh62"
      },
      "source": [
        "What is your interpretation of the residual plot?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "S1rRnmZ6Qh62"
      },
      "source": [
        "import scipy as sp\n",
        "\n",
        "# using the scipy bartlett function to get our test result and p-value\n",
        "YOUR CODE HERE\n",
        "\n",
        "# computing the critical value of a chi-squared distribution\n",
        "degree_of_freedom = len(y_pred) - 1\n",
        "prob = 1 - p_value\n",
        "critical_value = sp.stats.chi2.ppf(prob, degree_of_freedom)\n",
        "\n",
        "print(\"Critical value:\", critical_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SG5NrEkQh66"
      },
      "source": [
        "If the test result of our Bartlett test is greater than the critical value of the chi-squared distribution, then we will reject our null value and conclude that the variances in our dataset are not equal, i.e., they are heterogeneous. Otherwise, we will accept that this dataset's variances are homogeneous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us_BSW8IQh66"
      },
      "source": [
        "if (test_result > critical_value):\n",
        "    print(\" The variances are heterogeneous (unequal), and the model needs to be reassessed.\")\n",
        "else:\n",
        "    print('The variances are homogeneous (equal).')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAUKeNzSQh6-"
      },
      "source": [
        "### 4.2 Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnvFvtd7Qh6-"
      },
      "source": [
        "We can try boosting to see if it will improve our model. We will experiment with 3 types of boosting:\n",
        "- Ada Boosting\n",
        "- Gradient Boosting\n",
        "- eXtreme Gradient (XG) Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE1xdEIFQh6_"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# creating a list of learning rates to use as hyperparameters\n",
        "learning_rates = [0.1, 0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "# setting up our Ada booster\n",
        "for lr in learning_rates:\n",
        "    ada = AdaBoostRegressor(learning_rate = lr, random_state = 0)\n",
        "    ada.fit(X_train, y_train)\n",
        "    ada_predict = ada.predict(X_test)\n",
        "    print(\"Ada Boosting Regression with Learning Rate:\", lr)\n",
        "    print(\"RMSE Score:\", np.sqrt(metrics.mean_squared_error(y_test, ada_predict)))\n",
        "    print()\n",
        "    \n",
        "print(\"***************************************************\") \n",
        "\n",
        "# setting up our Gradient booster\n",
        "for lr in learning_rates:\n",
        "    gradient = GradientBoostingRegressor(learning_rate = lr, random_state = 0)\n",
        "    gradient.fit(X_train, y_train)\n",
        "    gradient_predict = gradient.predict(X_test)\n",
        "    print(\"Gradient Boosting Regression with Learning Rate:\", lr)\n",
        "    print(\"RMSE Score:\", np.sqrt(metrics.mean_squared_error(y_test, gradient_predict)))\n",
        "    print()\n",
        "\n",
        "print(\"***************************************************\")\n",
        "\n",
        "# setting up our XG booster\n",
        "for lr in learning_rates:\n",
        "    xgbr = XGBRegressor(learning_rate = lr, random_state = 0)\n",
        "    xgbr.fit(X_train, y_train)\n",
        "    xgbr_predict = xgbr.predict(X_test)\n",
        "    print(\"XG Boosting Regression with Learning Rate:\", lr)\n",
        "    print(\"RMSE Score:\", np.sqrt(metrics.mean_squared_error(y_test, xgbr_predict)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjArZYttQh7C"
      },
      "source": [
        "print(\"Ada Boosting R-squared Score:\", metrics.r2_score(y_test, ada_predict))\n",
        "print(\"Gradient Boosting R-squared Score:\", metrics.r2_score(y_test, gradient_predict))\n",
        "print(\"XG Boosting R-squared Score:\", metrics.r2_score(y_test, xgbr_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gccFwmX3Qh7K"
      },
      "source": [
        "From the above analysis, we see that XG Boosting with a learning rate of 0.1 returned the lowest RMSE score (125,974). Although still higher than 10% of the target variable mean, it is a better score than that of the original linear regression. Also, the r-squared score of XG Boosting is 0.8 which means it fits about 80% of our data, which is much better than for linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI8eUGi1Qh7K"
      },
      "source": [
        "## <font color='#2F4F4F'>5. Summary of Findings</font>\n",
        "\n",
        "Our dataset met most of the assumptions for multiple linear regression such as normality and homoscedasticity. However, the assumptions on linearity, multicollinearity, and outliers were not fully met, thereby proving to be a poor data for multiple linear regression.\n",
        "\n",
        "With XG Boosting, the model fit to about 80% of the data, thereby meeting our metric for success."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P75v8gwNQh7L"
      },
      "source": [
        "## <font color='#2F4F4F'>6. Recommendations</font>\n",
        "\n",
        "I would recommend that Knightly Frankly use XG Boost Regressor rather than Multiple Linear Regression to predict the prices of the houses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRNNw7WVQh7M"
      },
      "source": [
        "## <font color='#2F4F4F'>7. Challenging your Solution</font>\n",
        "\n",
        "#### a) Did we have the right question?\n",
        "Yes.\n",
        "\n",
        "#### b) Did we have the right data?\n",
        "Yes.\n",
        "\n",
        "#### c) What can be done to improve the solution?\n",
        "Apart from carrying out hyperparameter tuning, we can implement cross validation. Alternatively, we can try out other regression analysis models."
      ]
    }
  ]
}